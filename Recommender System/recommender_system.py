# -*- coding: utf-8 -*-
"""Recommender_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17Jdl7rWtXY4gBfqiEBGKVp_5QKv6t7yk

## Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
import random
from google.colab import drive
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.metrics.pairwise import cosine_similarity
from tensorflow import keras
from tensorflow.keras import layers

"""## Load data"""

drive.mount('/content/drive')

cellphones = pd.read_csv('/content/drive/MyDrive/Dicoding_MLT/cellphones data.csv')
rating = pd.read_csv('/content/drive/MyDrive/Dicoding_MLT/cellphones ratings.csv')
users = pd.read_csv('/content/drive/MyDrive/Dicoding_MLT/cellphones users.csv')

cellphones.head()

rating.head()

users.head()

"""## EDA (Univariate)

deskripsi variabel
"""

cellphones.info()

cellphones.describe()

cellphones.describe(include=object)

print("Nilai unik dari DataFrame 'cellphones':")
for column in cellphones.columns:
    unique_values = cellphones[column].unique()
    print(f"\nKolom '{column}':")
    print(unique_values)

rating.info()

rating.describe()

print("\nNilai unik dari DataFrame 'rating':")
for column in rating.columns:
    unique_values = rating[column].unique()
    print(f"\nKolom '{column}':")
    print(unique_values)

users.info()

users.describe()

users.describe(include=object)

print("\nNilai unik dari DataFrame 'users':")
for column in users.columns:
    unique_values = users[column].unique()
    print(f"\nKolom '{column}':")
    print(unique_values)

"""Pada proses diatas adalah hasil dari statitstik deskriptif untuk data cellphone, seperti jumlah data yang valid (tidak kosong), rata-rata(mean), nilai maksimun dan mininum, dan juga nilai dari kategori unik yang ada dalam setiap fitur. Terdapat beberapa point penting:
- fitur rating, terdapat nilai 18 (seharusnya max 10)
- fitur model, terdapat inkonsistensi pada data karena adanya penggunaan tahun walaupun fitur releas date sudah ada
- fitur date, merubah tipe data tanggal
- fitur gender, 'select gender' akan diubah menjadi unknown
- fitur occupation, banyak nya nilai uniqe yang bermakna sama dan juga banyak data yang tidak konsisten.

## Data Processing

**merge all data**

Selanjutnya adalah melakukan penggabungan data. Dengan melakukan penggabungan data ini, maka tiap fitur akan memiliki informasi yang lebih berkesinambungan yang akan meningkatkan keakurasian dari hasil sistem rekomendasi sehingga memungkinkan agar hasil rekomendasi ini lebih berfokus pada personal recommendation
"""

merged_df = pd.merge(rating, cellphones, on='cellphone_id', how='inner')
print("DataFrame setelah menggabungkan 'rating' dan 'cellphones':")
merged_df.info()

final_merged_df = pd.merge(merged_df, users, on='user_id', how='inner')
print("\nDataFrame setelah menggabungkan dengan 'users':")
final_merged_df.info()

final_merged_df.head(10)

"""## Data Preparation"""

df_preparation = final_merged_df.copy()

"""**Memperbaiki fitur rating**

Membatasi nilai dalam kolom 'rating' antara 1 dan 10 dengan fungsi clip()
"""

df_preparation['rating'] = df_preparation['rating'].clip(lower=1, upper=10)

# Verifikasi setelah perbaikan
print("Statistik kolom 'rating' setelah perbaikan di df_preparation:")
print(df_preparation['rating'].describe())

"""**Memperbaiki fitur gender**

Nilai '-Select Gender-' kemungkinan merupakan nilai placeholder atau nilai default yang muncul ketika pengguna tidak memilih jenis kelamin secara spesifik. Menggantinya dengan 'Unknown' menciptakan representasi yang lebih standar dan konsisten untuk data yang tidak teridentifikasi.
"""

# Mengganti '-Select Gender-' dengan 'Unknown'
df_preparation['gender'] = df_preparation['gender'].replace('-Select Gender-', 'Unknown')

print(df_preparation['gender'].unique())

"""**Memperbaiki Fitur Occupation**

Tujuan dari kode ini adalah untuk mengelompokkan dan menstandarkan berbagai jenis pekerjaan (occupation) ke dalam kategori yang lebih umum dan terstruktur. Ini dilakukan dengan menggunakan sebuah mapping dictionary (occupation_mapping).
"""

occupation_mapping = {
    'team worker in it': 'IT',
    'it': 'IT',
    'information technology': 'IT',
    'information': 'IT',
    'Information Technology': 'IT',
    'Information technology': 'IT',
    'WEB DESIGN': 'IT',
    'software developer': 'IT',
    'ict officer': 'IT',
    'technical engineer': 'Engineer',
    'engineer': 'Engineer',
    'manager': 'Manager',
    'Manager': 'Manager',
    'MANAGER': 'Manager',
    'Ops Manager': 'Manager',
    'QA Software Manager': 'Manager',
    'Executive Manager': 'Executive',
    'executive': 'Executive',
    'accountant': 'Finance',
    'Accountant': 'Finance',
    'FINANCE': 'Finance',
    'Finance': 'Finance',
    'sales': 'Sales',
    'Sales': 'Sales',
    'SALES MANAGER': 'Sales',
    'teacher': 'Education',
    'EDUCATION': 'Education',
    'Education': 'Education',
    'healthcare': 'Healthcare',
    'Healthcare': 'Healthcare',
    'HEALTHARE': 'Healthcare',
    'HEALTHCARE': 'Healthcare',
    'nurse': 'Healthcare',
    'banking': 'Finance',
    'finance': 'Finance',
    'administrator': 'Admin',
    'Administrator': 'Admin',
    'ADMINISTRATIVE OFFICER': 'Admin',
    'Administrative officer': 'Admin',
    'technician': 'Technical',
    'Computer technician': 'Technical',
    'marketing': 'Marketing',
    'Marketing': 'Marketing',
    'writer': 'Other',
    'registered': 'Other',
    'business': 'Other',
    'Transportation': 'Other',
    'president transportation company': 'Transportation',
    'construction': 'Other',
    'master degree': 'Education',
    'Warehousing': 'Other',
    'self employed': 'Other',
    'retail': 'Sales',
    'homemaker': 'Other',
    'Purchase Manager': 'Manager',
    'System Administrator': 'IT',
    'Security': 'Technical',
    'Team leader': 'Other',
    'team leader': 'Other',
    'worker': 'Other',
    'doctor': 'Healthcare',
    np.nan: 'Unknown'
}
df_preparation['occupation'] = df_preparation['occupation'].map(occupation_mapping).fillna(df_preparation['occupation'])

print(df_preparation['occupation'].unique())

"""**Memperbaikin fitur release date**

Selanjutnya adalah melakukan perubahan format data pada kolom 'release date' menjadi tipe data datetime yang dikenali oleh Pandas dengan menggunakan fungsi to_datetime().
"""

# Mengonversi kolom 'release date' ke format datetime Pandas
df_preparation['release date'] = pd.to_datetime(df_preparation['release date'], format='%d/%m/%Y', errors='coerce')
print("Nilai unik dan tipe data kolom 'release date' setelah konversi:")
print(df_preparation['release date'].unique())
print(df_preparation['release date'].dtype)

"""**memperbaiki fitur model**

membersihkan dan menstandarkan data pada kolom 'model' dengan melakukan dua jenis penggantian string
- Mengganti non-breaking space : Menggantinya dengan spasi biasa memastikan konsistensi dan mencegah kesalahan saat membandingkan atau menganalisis nama model.
- Menghapus informasi tahun yang berada di dalam tanda kurung: membersihkan nama model dari informasi tahun rilis, yang sebenarnya sudah ada di fitur release date
"""

# Mengganti non-breaking space dengan spasi biasa
df_preparation['model'] = df_preparation['model'].str.replace('\xa0', ' ', regex=False)

# Menghapus informasi tahun yang berada di dalam tanda kurung
df_preparation['model'] = df_preparation['model'].str.replace(r'\s*\(\d{4}\)', '', regex=True).str.strip()
print("\nNilai unik kolom 'model' setelah menghapus tahun:")
print(df_preparation['model'].unique())

df_preparation.info()

"""**cek missing value**"""

df_preparation.isnull().sum()

"""- tidak ditemukan adanya missing value

**cek duplicate**
"""

duplicate_count = df_preparation.duplicated().sum()
print(f"Jumlah Data Duplikat: {duplicate_count}")

"""- tidak ditemukan adanya duplikat"""

df_preparation.sample(20)

"""## Model Development

**Model Development dengan Content Based Filtering**

**data preparation**
"""

# Pilih Fitur Relevan untuk Content-Based
features = ['brand', 'operating system', 'internal memory', 'RAM', 'performance',
            'main camera', 'selfie camera', 'battery size', 'screen size', 'price']
content_df = df_preparation[features + ['user_id', 'model', 'cellphone_id', 'rating']].copy()

# Pra-proses Fitur: One-Hot Encode fitur kategorikal
content_df = pd.get_dummies(content_df, columns=['brand', 'operating system'])

# Pra-proses Fitur: Scaling fitur numerik
numeric_features = ['internal memory', 'RAM', 'performance', 'main camera',
                    'selfie camera', 'battery size', 'screen size', 'price']
scaler = MinMaxScaler()
content_df[numeric_features] = scaler.fit_transform(content_df[numeric_features])

print("\nDataFrame content_df setelah pra-pemrosesan untuk Content-Based Filtering:")
content_df.head()

"""Kode ini bertujuan untuk mempersiapkan data agar sesuai untuk digunakan dalam model Content-Based Filtering. Fokusnya adalah pada pembuatan representasi fitur untuk setiap item (ponsel) berdasarkan atribut-atributnya. Beberapa hal penting yang dapat kita amati:
- Fitur Numerik yang Di-scaling sehingga memiliki nilai dalam rentang antara 0 dan 1 dengan menggunakan MinMaxScaler.
-Encoding Fitur Kategorikal menggunakan One-Hot Encoder

**membuat item profile (HP)**

dilakukan penhitungan untuk item profil (cellphone) untuk setiap model ponsel dengan mengambil rata-rata (mean) dari fitur-fitur numerik yang telah diproses sebelumnya (melalui one-hot encoding dan scaling).
"""

# Membuat Profil Item (HP) berdasarkan rata-rata fitur
item_profiles = content_df.groupby('model')[content_df.select_dtypes(include=np.number).columns].mean()

print("\nProfil Item (HP) untuk Content-Based Filtering:")
print(item_profiles.head())
print(f"Shape profil item: {item_profiles.shape}")

"""**menampilkan matrix cosine similiarity**

Dengan matriks cosine_sim_df, dapat dengan mudah diketahui seberapa mirip suatu model ponsel dengan model ponsel lainnya berdasarkan fitur-fitur yang digunkan untuk membuat profil item. Misalnya, jika nilai pada cosine_sim_df['Galaxy A32']['G Power'] tinggi, itu berarti kedua ponsel tersebut memiliki profil fitur yang serupa.
"""

# Menghitung Cosine Similarity antar Item Profiles
cosine_sim_items = cosine_similarity(item_profiles)

# Membuat DataFrame dari matriks Cosine Similarity
cosine_sim_df = pd.DataFrame(cosine_sim_items, index=item_profiles.index, columns=item_profiles.index)

print("\nMatriks Cosine Similarity Antar Item (HP):")
cosine_sim_df.sample(10)

"""**User Profile untuk Content-Based Filtering**

Membuat representasi numerik dari preferensi setiap pengguna berdasarkan item (dalam hal ini, ponsel) yang telah mereka beri rating tinggi.
"""

# Fungsi untuk membuat profil pengguna berdasarkan rating tinggi
def create_user_profile_cb(user_id, rating_threshold=4):
    rated_high = content_df[(content_df['user_id'] == user_id) & (content_df['rating'] >= rating_threshold)]
    if not rated_high.empty:
        user_profile = rated_high[content_df.select_dtypes(include=np.number).columns].mean()
        return user_profile
    else:
        return None

# Membuat profil pengguna untuk semua pengguna
user_profiles_cb = {}
for user in content_df['user_id'].unique():
    profile = create_user_profile_cb(user)
    if profile is not None:
        user_profiles_cb[user] = profile

"""Untuk setiap pengguna dalam dataset, kode ini mencari item yang mereka beri rating tinggi. Kemudian,  dihitung rata-rata fitur-fitur dari item-item tersebut untuk membuat "profil" yang merepresentasikan apa yang disukai pengguna tersebut. Profil-profil ini kemudian disimpan untuk digunakan dalam merekomendasikan item baru kepada pengguna berdasarkan kemiripan fitur dengan profil mereka."""

print("\nHasil Beberapa Profil Pengguna (Content-Based) :")
for i, (user_id, profile) in enumerate(user_profiles_cb.items()):
    if i < 5:
        print(f"User ID: {user_id}, Profil:\n{profile.head()}")
    if i == 5:
        break
print(f"\nJumlah profil pengguna (Content-Based) yang berhasil dibuat: {len(user_profiles_cb)}")

"""**Rekomendasi Content Based**

Mengimplementasikan sistem rekomendasi content-based filtering. Fungsi ini mengambil profil pengguna dan item, menghitung kemiripan antara profil pengguna dan setiap item, dan mengembalikan daftar item yang paling mirip (dan belum di-rating oleh pengguna) sebagai rekomendasi.
"""

# Fungsi untuk memberikan rekomendasi Content-Based
def recommend_content_based(user_id, user_profiles, item_profiles, content_df, top_n=5):
    user_profile = user_profiles.get(user_id)
    if user_profile is None:
        return f"Pengguna dengan ID {user_id} tidak memiliki rating tinggi."

    similarity_scores = cosine_similarity([user_profile], item_profiles)[0]
    similarity_df = pd.DataFrame({'model': item_profiles.index, 'similarity': similarity_scores})
    # pengecualian item yang sudah di rating
    rated_items = content_df[content_df['user_id'] == user_id]['model'].unique()
    recommendations = similarity_df[~similarity_df['model'].isin(rated_items)].sort_values(by='similarity', ascending=False).head(top_n)
    return recommendations

# Contoh rekomendasi Content-Based untuk user_id=1
recommendations_user_1_cb = recommend_content_based(1, user_profiles_cb, item_profiles, content_df)
print("\nRekomendasi Content-Based untuk User ID 1:")
print(recommendations_user_1_cb)

"""**Model Development dengan Collaborative Filltering**

data preparation

Mempersiapkan data untuk tugas collaborative filtering menggunakan model neural network. Langkah-langkah utamanya adalah:

- Mengubah ID pengguna dan item menjadi indeks numerik berurutan.
- Membagi data menjadi set pelatihan dan pengujian.
- Membuat TensorFlow Dataset yang efisien untuk memproses data selama pelatihan dan evaluasi model.
- Menskalakan nilai rating ke rentang 0-1.
"""

# Konversi ID ke Numerik Berurutan
user_encoder = LabelEncoder()
df_preparation['user_index'] = user_encoder.fit_transform(df_preparation['user_id'])
item_encoder = LabelEncoder()
df_preparation['item_index'] = item_encoder.fit_transform(df_preparation['cellphone_id'])
num_users = len(user_encoder.classes_)
num_items = len(item_encoder.classes_)

# Split Data
train_df, test_df = train_test_split(df_preparation, test_size=0.2, random_state=42)

# Buat TensorFlow Dataset
def create_tf_dataset(df):
    user_ids = df['user_index'].values
    item_ids = df['item_index'].values
    ratings = df['rating'].values.astype(np.float32) / 5.0 # Skalakan rating ke 0-1
    stacked_ids = np.stack((user_ids, item_ids), axis=1)
    return tf.data.Dataset.from_tensor_slices((stacked_ids, ratings))

train_dataset = create_tf_dataset(train_df).batch(64).prefetch(tf.data.AUTOTUNE)
test_dataset = create_tf_dataset(test_df).batch(64).prefetch(tf.data.AUTOTUNE)

"""modelling

RecommenderNetV2: Model rekomendasi collaborative filtering dengan arsitektur NN yang lebih dalam untuk mempelajari pola interaksi pengguna-item.
"""

# Definisikan Model (RecommenderNet) dengan lebih banyak layer dan dropout
class RecommenderNetV2(tf.keras.Model):
    def __init__(self, num_users, num_items, embedding_size, hidden_units, dropout_rate=0.1, **kwargs):
        super(RecommenderNetV2, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_items = num_items
        self.embedding_size = embedding_size
        self.user_embedding = layers.Embedding(num_users, embedding_size, embeddings_initializer='he_normal', embeddings_regularizer=keras.regularizers.l2(1e-6))
        self.user_bias = layers.Embedding(num_users, 1)
        self.item_embedding = layers.Embedding(num_items, embedding_size, embeddings_initializer='he_normal', embeddings_regularizer=keras.regularizers.l2(1e-6))
        self.item_bias = layers.Embedding(num_items, 1)
        self.dense_1 = layers.Dense(hidden_units, activation='relu')
        self.dropout_1 = layers.Dropout(dropout_rate)
        self.dense_2 = layers.Dense(hidden_units // 2, activation='relu')
        self.dropout_2 = layers.Dropout(dropout_rate)
        self.dense_output = layers.Dense(1, activation='sigmoid')

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        item_vector = self.item_embedding(inputs[:, 1])
        item_bias = self.item_bias(inputs[:, 1])
        dot_user_item = tf.tensordot(user_vector, item_vector, 2)
        x = dot_user_item + user_bias + item_bias
        x = self.dense_1(x)
        x = self.dropout_1(x)
        x = self.dense_2(x)
        x = self.dropout_2(x)
        return self.dense_output(x)

"""compile dan train

Menginstansiasi model RecommenderNetV2 dengan konfigurasi tertentu (ukuran embedding, jumlah hidden unit, dropout rate), mengompilasinya dengan optimizer, fungsi loss, dan metrik yang sesuai, serta melatihnya dengan data yang telah disiapkan menggunakan early stopping untuk mencegah overfitting dan mendapatkan model dengan kinerja terbaik.
"""

# Instansiasi dan Kompilasi Model yang Lebih Baik
embedding_size = 64
hidden_units = 128
dropout_rate = 0.2
model = RecommenderNetV2(num_users, num_items, embedding_size, hidden_units, dropout_rate)
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),
    loss=tf.keras.losses.MeanSquaredError(),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Latih Model dengan lebih banyak epoch dan early stopping
epochs = 30
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
history = model.fit(
    train_dataset,
    epochs=epochs,
    validation_data=test_dataset,
    callbacks=[early_stopping]
)

"""**Rekomendasi Collaborative Filltering**

Menghasilkan rekomendasi HP yang dipersonalisasi untuk pengguna berdasarkan preferensi pengguna lain yang serupa, menggunakan model Neural Collaborative Filtering yang telah dilatih.
"""

def recommend_top_n_neural_cf_final_unique_simplified(user_id, model, user_encoder, item_encoder, df, top_n=10):
    try:
        user_index = user_encoder.transform([user_id])[0]
    except KeyError:
        return f"User ID {user_id} tidak ditemukan dalam data."

    items_rated_by_user = df[df['user_id'] == user_id]['item_index'].unique()
    all_item_indices = np.arange(len(item_encoder.classes_))
    items_to_predict = np.setdiff1d(all_item_indices, items_rated_by_user)

    if not items_to_predict.size:
        return f"Pengguna {user_id} telah menilai semua HP yang tersedia."

    user_input = np.expand_dims(np.array([user_index] * len(items_to_predict)), axis=1)
    item_input = np.expand_dims(items_to_predict, axis=1)

    predictions = model.predict(np.concatenate([user_input, item_input], axis=1))

    top_n_indices = np.argsort(predictions, axis=0)[::-1][:top_n].flatten()
    recommended_item_indices = items_to_predict[top_n_indices]
    recommended_item_ids = item_encoder.inverse_transform(recommended_item_indices)
    predicted_ratings = predictions[top_n_indices].flatten()

    # Buat DataFrame hasil rekomendasi dengan peringkat dan predicted rating
    recommendation_df = pd.DataFrame({'cellphone_id': recommended_item_ids,
                                      'Predicted Rating (Scaled 0-1)': predicted_ratings,
                                      'Peringkat': range(1, top_n + 1)})

    # Gabungkan dengan detail unik HP dari DataFrame asli
    unique_hp_details = df.drop_duplicates(subset='cellphone_id')
    final_recommendations = pd.merge(recommendation_df, unique_hp_details, on='cellphone_id', how='left')

    # Pilih kolom detail HP yang ingin ditampilkan
    columns_to_display = ['Peringkat', 'cellphone_id', 'brand', 'model', 'operating system',
                          'internal memory', 'RAM', 'performance', 'main camera',
                          'selfie camera', 'battery size', 'screen size', 'weight',
                          'price', 'release date', 'Predicted Rating (Scaled 0-1)']

    return final_recommendations[columns_to_display]

"""mendemonstrasikan bagaimana sistem rekomendasi Collaborative Filtering berbasis Neural Network yang telah dilatih agar menghasilkan rekomendasi yang dipersonalisasi untuk pengguna dengan memilih pengguna secara acak dan menampilkan 10 rekomendasi teratas beserta detail HP."""

# Pilih User ID secara acak dari data untuk Collaborative Filtering
unique_user_ids_cf = df_preparation['user_id'].unique()
random_user_id_cf = random.choice(unique_user_ids_cf)
print(f"\nTop 10 Rekomendasi (Neural CF) dengan Detail HP untuk User ID Acak: {random_user_id_cf}")
top_10_recommendations_random_user_cf = recommend_top_n_neural_cf_final_unique_simplified(
    random_user_id_cf, model, user_encoder, item_encoder, df_preparation, top_n=10
)
top_10_recommendations_random_user_cf

"""## Evaluasi

mengukur seberapa baik model yang telah dilatih dapat melakukan generalisasi ke data baru dan tidak dikenal. Loss dan RMSE pada test set memberikan indikasi kinerja model yang sebenarnya.
"""

# Evaluasi Model
loss, rmse = model.evaluate(test_dataset)
print(f"\nLoss on test set (Neural CF): {loss:.4f}")
print(f"RMSE on test set (Neural CF): {rmse:.4f}")

"""Selanjutnya melkukan plotting dari hasil pelatihan model"""

import matplotlib.pyplot as plt

# Ambil riwayat pelatihan dari objek history
history_dict = history.history

loss_values = history_dict['loss']
val_loss_values = history_dict['val_loss']
rmse_values = history_dict['root_mean_squared_error']
val_rmse_values = history_dict['val_root_mean_squared_error']

epochs = range(1, len(loss_values) + 1)

# Plot Loss
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, loss_values, 'bo-', label='Training Loss')
plt.plot(epochs, val_loss_values, 'ro-', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plot RMSE
plt.subplot(1, 2, 2)
plt.plot(epochs, rmse_values, 'bo-', label='Training RMSE')
plt.plot(epochs, val_rmse_values, 'ro-', label='Validation RMSE')
plt.title('Training and Validation RMSE')
plt.xlabel('Epochs')
plt.ylabel('RMSE')
plt.legend()

plt.tight_layout()
plt.show()